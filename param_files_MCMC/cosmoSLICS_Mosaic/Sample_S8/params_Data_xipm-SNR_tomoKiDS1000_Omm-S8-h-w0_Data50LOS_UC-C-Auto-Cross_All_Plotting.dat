# Parameter file for input to Cosmic_Banana.py

# --------------------------------------------------------------------- GENERAL ANALYSIS ------------------------------------------------------------------------------
Use_Stats = []
Combine_Stats = [range(16,31),range(16,31),range(16,31)]
	#[1,6,10,13,15]         # AUTO PDF(3.3arcmin)
	#[16,21,25,28,30]		# AUTO PDF(6.6arcmin)
	#[31,36,40,43,45]       # AUTO PDF(13.2arcmin)

	# range(1,16)           # AUTO & CROSS PDF(3.3 arcmin)
	# range(16,31)          # AUTO & CROSS PDF(6.6arcmin)
	# range(31,46)          # AUTO & CROSS PDF(13.2arcmin)
	# range(1,46)           # AUTO & CROSS PDF(3.3,6.6,13.2 arcmin)

	# UNCLIPPED
	#[46,51,55,58,60]       # auto-xi+
	# range(46,61)        	# auto & cross xi+
	# [61,66,70,73,75]      # auto-xi-
	# range(61,76)          # auto & cross xi-
	# range(46,76)          # auto & cross xi+/-

	# CLIPPED
	# range(76,91)          # auto & cross xi+^clip
	# range(91,106)         # auto & cross xi-^clip
	# range(76,106)         # auto & cross xi+/-^clip

	# CLIPPED & UNCLIPPED
	# np.append(range(76,106),range(46,76))   # auto & cross xi+/- unclip & clip

	# -x-x-x-x-x- NO TOMOGRAPHY -x-x-x-x-x-x-x-
	# [106,107]  # xi+/-, No Tomo
	# [108,109]  # xi+/-^clip, No Tomo
	# [108,109,106,107]  # clip & unclip, No Tomo
	
	# [110,111,112]  # PDF(3 scales), No Tomo
	
	
	# Which statistics to combine, e.g. [[1,2,3], [4,5]] means
	# combine stats 1&2&3 and separately combine 4&5. Empty means no combinations.

OneD_TwoD_Or_nD = nD																	# Variable specifying if it's a 2D grid, 1D line or nD MCMC likelihood problem.

DataNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_Fid.txt

DataNodesCols = [0,1,2,3]																# Which columns to pull out of DataNodesFile
	      	     # If 1 number, will do a 1D analysis, if 2 numbers, it'll do 2D.

Plot_Limits = [[0.10,0.50],[0.68,0.92],[0.55,0.85],[-2.0,-0.4]]
Apply_Hartlap = True

# Plotting variables
DataLabel = ''
nLabels = [r'$\Omega_{\rm{m}}$',r'$S_8$',r'$h$',r'$w_0$']
savedirectory = Results_MCMC/DatacosmoSLICS_50LOS_Mosaic/SNR_vs_xip_tomo15bins_Omm-S8


# --------------------------------------------------------------------- MCMC SETTINGS ------------------------------------------------------------------------------
nwalkers = 120					
burn_steps = 200			
real_steps = 800



# --------------------------------------------------------------------- STATISTIC 1 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.1-0.3/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 2 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.1-0.3_X_ZBcut0.3-0.5/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 3 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.1-0.3_X_ZBcut0.5-0.7/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 4 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.1-0.3_X_ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 5 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.1-0.3_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy





# --------------------------------------------------------------------- STATISTIC 6 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.3-0.5/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 7 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.3-0.5_X_ZBcut0.5-0.7/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 8 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.3-0.5_X_ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 9 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.3-0.5_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 10 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.5-0.7/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 11 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.5-0.7_X_ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 12 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.5-0.7_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 13 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_CosmolXXXX/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_Cosmolfid/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'greenyellow'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 14 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'greenyellow'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.7-0.9_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 15 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS3.3arcmin/ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy








# --------------------------------------------------------------------- STATISTIC 16 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.1-0.3/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 17 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.1-0.3_X_ZBcut0.3-0.5/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 18 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.1-0.3_X_ZBcut0.5-0.7/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 19 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.1-0.3_X_ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 20 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.1-0.3_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy





# --------------------------------------------------------------------- STATISTIC 21 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.3-0.5/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 22 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.3-0.5_X_ZBcut0.5-0.7/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 23 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.3-0.5_X_ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 24 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.3-0.5_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 25 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.5-0.7/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 26 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.5-0.7_X_ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 27 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.5-0.7_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 28 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_CosmolXXXX/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_Cosmolfid/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'greenyellow'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.7-0.9/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 29 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'greenyellow'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.7-0.9_X_ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 30 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/SNR/SS6.6arcmin/ZBcut0.9-1.2/HPs_PDF_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy




# --------------------------------------------------------------------- STATISTIC 31 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 32 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 33 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =

# --------------------------------------------------------------------- STATISTIC 34 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 35 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File =



# --------------------------------------------------------------------- STATISTIC 36 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 37 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 38 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 39 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/SN0.258_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 40 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =

# --------------------------------------------------------------------- STATISTIC 41 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =

# --------------------------------------------------------------------- STATISTIC 42 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/SN0.273_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 43 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_CosmolXXXX/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_Cosmolfid/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'greenyellow'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =

# --------------------------------------------------------------------- STATISTIC 44 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/SN0.254_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 13.2\, \rm{arcmin}$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'greenyellow'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =


# --------------------------------------------------------------------- STATISTIC 45 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_CosmolXXXX/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.dat 
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_Cosmolfid/SN0.27_Mosaic.KiDS1000GpAM.LOSAll.SS5.631.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 60\, \rm{arcmin}$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4  
n_restarts_optimizer = 0

HPs_File =
















# --------------------------------------------------------------------- STATISTIC 46 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.1-0.3/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 47 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.3-0.5/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 48 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.5-0.7/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 49 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 50 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 51 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.3-0.5/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 52 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.5-0.7/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 53 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 54 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 55 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.5-0.7_X_ZBcut0.5-0.7/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 56 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.5-0.7_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 57 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.5-0.7_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 58 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.7-0.9_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 59 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.7-0.9_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy




# --------------------------------------------------------------------- STATISTIC 60 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.9-1.2_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy









# --------------------------------------------------------------------- STATISTIC 61 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.1-0.3/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 62 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.3-0.5/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 63 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.5-0.7/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 64 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 65 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 66 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.3-0.5/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 67 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.5-0.7/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 68 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 69 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 70 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.5-0.7_X_ZBcut0.5-0.7/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 71 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.5-0.7_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 72 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.5-0.7_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 73 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.7-0.9_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 74 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.7-0.9_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy




# --------------------------------------------------------------------- STATISTIC 75 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.9-1.2_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy











# xxxxxxxxxx THE CLIPPED STATS xxxxxxxxxxxxx


# --------------------------------------------------------------------- STATISTIC 76 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.1-0.3/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 77 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.3-0.5/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 78 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.5-0.7/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 79 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 80 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.1-0.3_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 81 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.3-0.5/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 82 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.5-0.7/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 83 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 84 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.3-0.5_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 85 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.5-0.7_X_ZBcut0.5-0.7/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 86 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.5-0.7_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 87 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.5-0.7_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 88 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.7-0.9_X_ZBcut0.7-0.9/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 89 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xip/ZBcut0.7-0.9_X_ZBcut0.9-1.2/HPs_xip_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy




# --------------------------------------------------------------------- STATISTIC 90 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'green'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###

# --------------------------------------------------------------------- STATISTIC 91 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.1-0.3/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 92 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.3-0.5/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 93 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.5-0.7/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy



# --------------------------------------------------------------------- STATISTIC 94 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 95 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<0.3$'
PlotColour = 'darkred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.1-0.3_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 96 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.3-0.5_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.3-0.5/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 97 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.5-0.7/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy

# --------------------------------------------------------------------- STATISTIC 98 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 99 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.258_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.3-0.5_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.258_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.3<z_{\rm B}<0.5$'
PlotColour = 'indianred'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.3-0.5_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 100 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.5-0.7_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.5-0.7_X_ZBcut0.5-0.7/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 101 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.5-0.7_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 102 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.273_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.5-0.7_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.273_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.5<z_{\rm B}<0.7$'
PlotColour = 'darkorange'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.5-0.7_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy






# --------------------------------------------------------------------- STATISTIC 103 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.7-0.9_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.7-0.9_X_ZBcut0.7-0.9/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy


# --------------------------------------------------------------------- STATISTIC 104 ------------------------------------------------------------------------------

nBins = 9                                                                              # Number of bins in this statistic
Bins_To_Use = range(3,9)                                                              # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																	# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																			# The sky area this covariance was measured on
SurveyArea = 1000																		# Survey size you want to scale the cov to.
Nreal = 2170																			# Num realisations in cov  
																						# Used to calc Hartlap correction if Apply Hartlap is True.

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.254_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.7-0.9_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.254_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.7<z_{\rm B}<0.9$'
PlotColour = 'yellowgreen'


# --- EMULATOR SETTINGS --- #

Transform = xy1e4    # Transform to perform on input data
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =
###/home/bengib/Calc_Lhd_Tool/HPs/cosmoSLICS/KiDS1000_NoMosiac_Omm-S8-h-w0/xim/ZBcut0.7-0.9_X_ZBcut0.9-1.2/HPs_xim_N26_IncludexFalse_PCATrue_ScaleNodesFalse_ErrorNone_TrainedOnCS.npy




# --------------------------------------------------------------------- STATISTIC 105 ------------------------------------------------------------------------------

nBins = 9  
Bins_To_Use = range(9)  

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc


PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']							
PredCols = [0,1]															

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
														
PredNodesCols = [0,1,2,3]														

CovFile = 

CovArea = 1000
SurveyArea = 1000															
Nreal = 217

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2_X_ZBcut0.9-1.2_Cosmolfid/ThBins9/NLOS900/SN0.27_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.9<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'


Transform = xy1e4    
Perform_PCA = True
n_components = 6   
n_restarts_optimizer = 0

HPs_File =


# -x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x- NO-TOMOGRAPHIC CLIPPED & UNCLIPPED -x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-


# --------------------------------------------------------------------- STATISTIC 106 ------------------------------------------------------------------------------

nBins = 9
Bins_To_Use = range(9)

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.asc

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
PredCols = [0,1]

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
PredNodesCols = [0,1,2,3]

CovFile =

CovArea = 1000
SurveyArea = 1000
Nreal = 217

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_Cosmolfid/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+$, $0.1<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

Transform = xy1e4	
Perform_PCA = True
n_components = 6  
n_restarts_optimizer = 0
HPs_File =


# --------------------------------------------------------------------- STATISTIC 107 ------------------------------------------------------------------------------

nBins = 9
Bins_To_Use = range(9)

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.asc

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
PredCols = [0,1]

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
PredNodesCols = [0,1,2,3]

CovFile =

CovArea = 1000
SurveyArea = 1000
Nreal = 217

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_Cosmolfid/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-$, $0.1<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

Transform = xy1e4
Perform_PCA = True
n_components = 6  
n_restarts_optimizer = 0
HPs_File =

# --------------------------------------------------------------------- STATISTIC 108 ------------------------------------------------------------------------------

nBins = 9
Bins_To_Use = range(9)

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.asc

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
PredCols = [0,1]

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
PredNodesCols = [0,1,2,3]

CovFile =

CovArea = 1000
SurveyArea = 1000
Nreal = 217

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_Cosmolfid/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF+.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_+^c$, $0.1<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

Transform = xy1e4
Perform_PCA = True
n_components = 6  
n_restarts_optimizer = 0
HPs_File =



# --------------------------------------------------------------------- STATISTIC 109 ------------------------------------------------------------------------------

nBins = 9
Bins_To_Use = range(9)

PredFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_CosmolXXXX/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.asc

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']
PredCols = [0,1]

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt
PredNodesCols = [0,1,2,3]

CovFile =

CovArea = 1000
SurveyArea = 1000
Nreal = 217

DataFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_Cosmolfid/ThBins9/NLOS900/SN0.265_Mosaic.KiDS1000GpAM.NLOS900.SS2.816.rCLIP_X3sigma.AverageCF-.IAbias0.0-added.asc
DataCols = [0,1]

PlotLabel = r'$\xi_-^c$, $0.1<z_{\rm B}<1.2$'
PlotColour = 'deepskyblue'

Transform = xy1e4
Perform_PCA = True
n_components = 6  
n_restarts_optimizer = 0
HPs_File =

# --------------------------------------------------------------------- STATISTIC 110 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_CosmolXXXX/SN0.265_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_Cosmolfid/SN0.265_Mosaic.KiDS1000GpAM.LOSAll.SS1.408.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, $0.1<z_{\rm B}<1.2$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File = 

# --------------------------------------------------------------------- STATISTIC 111 ------------------------------------------------------------------------------

nBins = 4                                                                              # Number of bins in this statistic
Bins_To_Use = range(4)                                                                 # Which bins in prediction to use. range(<nBins>) for all.

PredFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_CosmolXXXX/SN0.265_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.dat
																						# General Filename of predictions 
																						# with 'XXXX' replacing the ID of the separate predictions
																						# Or one pickled file (*.npy) containing all predictions

PredIDs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,'fid']																				
																						# ID numbers to replace 'XXXX'. 
																						# If IDs are not numbers, or not sequential, put list here.
																						# e.g. ['a','b','c'], [1,3,5,7,9,11,...]

PredCols = [0,1]																			    # [OPTIONAL} If specified: Which 2 columns to read in PredFile 
																						# Assumed order: [x_col,y_col]. Else assumes x_col=0, y_col=1

PredNodesFile = /home/bengib/cosmoSLICS/Cosmologies/SLICS_Cosmol_Table_ExtraCol_NoHead_25plusFid.txt		
																						# File for coords (nodes) of the predictions
																						# Assumes each row is different node, columns are the different dimensions
PredNodesCols = [0,1,2,3]																# Which columns to pull out of PredNodesFile


CovFile = 

CovArea = 1000																				# The sky area this covariance was measured on
SurveyArea = 1000																				# Survey size you want to scale the cov to.

DataFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2_Cosmolfid/SN0.265_Mosaic.KiDS1000GpAM.LOSAll.SS2.816.SNRPDF_4bins.IAbias0.0-added.dat 
DataCols = [0,1]

PlotLabel = r'$\rm{PDF}(SNR) \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, $0.1<z_{\rm B}<1.2$'
PlotColour = 'darkred'

# --- EMULATOR SETTINGS --- #

Transform = log    # Transform to perform on input data
Perform_PCA = True
n_components = 4    
n_restarts_optimizer = 0

HPs_File = 

# --------------------------------------------------------------------- END OF STATISTICS ------------------------------------------------------------------------------







#x#x#x#x#x SNR Combinations #x#x#x#x#x

#### AUTO CORR's #####

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS1.408.SNRPDF_4bins.zbins1-2-3-4-5.CovMat.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000																			# Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$, auto-only'
PlotColour = 'lightgreen'

SmoothContour = False                                           # Can optionally Gaussian smooth the likelihood contours if they're noisy
SmoothScale = 2													# standev of smoothin kernel, in units of pxls on the grid.

CombName = SNR-SS3.3arcmin-tomo5bins_IA0.0-added 

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.zbins1-2-3-4-5.CovMat.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000																			# Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$, auto-only'
PlotColour = 'green'

CombName = SNR-SS6.6arcmin-tomo5bins_IA0.0-added 


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS5.631.SNRPDF_4bins.zbins1-2-3-4-5.CovMat.npy

CovArea = 1000                      
SurveyArea = 1000                   

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 13.2 \, \rm{arcmin}$, auto-only'
PlotColour = 'darkred'

CombName = SNR-SS13.2arcmin-tomo5bins_IA0.0-added 



# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS1.408-2.816-5.631.SNRPDF_4bins.zbins1-2-3-4-5.CovMat.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000																			# Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF}$ Combined, auto-only'
PlotColour = 'orange'

SmoothContour = False                                           # Can optionally Gaussian smooth the likelihood contours if they're noisy
SmoothScale = 2													# standev of smoothin kernel, in units of pxls on the grid.

CombName = SNR-SS3.3arcmin-6.6arcmin-13.2arcmin-tomo5bins_IA0.0-added 


#### CROSS CORR's #####

# --------------------------------------------------------------------- COMBINATION X -----------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS1.408.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000                     # The sky area this covariance was measured on
SurveyArea = 1000                 # Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 3.3 \, \rm{arcmin}$'
PlotColour = 'lightgreen'

SmoothContour = False                                           # Can optionally Gaussian smooth the likelihood contours if they're noisy
SmoothScale = 2                                                 # standev of smoothin kernel, in units of pxls on the grid.

CombName = SNR-SS3.3arcmin-tomo15bins_IA0.0-added 



# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000																			# Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$; Old cov'
PlotColour = 'darkgreen'

CombName = SNR-SS6.6arcmin-tomo15bins_IA0.0-added 




# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000                                                                       
SurveyArea = 1000                                                                    

Nreal = 2170

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$'
PlotColour = 'lightgreen'

CombName = SNR-SS6.6arcmin-tomo15bins_NrealCov2170


# --------------------------------------------------------------------- COMBINATION 1 ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000
SurveyArea = 1000

Nreal = 2170

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin} \, A_{\rm ia} = -3.0$; '
PlotColour = 'darkgreen'

CombName = SNR-SS6.6arcmin-tomo15bins_NrealCov2170_IA-3.0-added



# --------------------------------------------------------------------- COMBINATION 2 ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000                                                                       
SurveyArea = 1000                                                                    

Nreal = 2170

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin} \, A_{\rm ia} = 0.0$; '
PlotColour = 'lightgreen'

CombName = SNR-SS6.6arcmin-tomo15bins_NrealCov2170_IA0.0-added 



# --------------------------------------------------------------------- COMBINATION 3 ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000
SurveyArea = 1000

Nreal = 2170

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin} \, A_{\rm ia} = 3.0$; '
PlotColour = 'yellow'

CombName = SNR-SS6.6arcmin-tomo15bins_NrealCov2170_IA3.0-added



# --------------------------------------------------------------------- COMBINATION X -----------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS5.631.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000                               # The sky area this covariance was measured on
SurveyArea = 1000                           # Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 13.2 \, \rm{arcmin}$'
PlotColour = 'red'

CombName = SNR-SS13.2arcmin-tomo15bins_IA0.0-added 





# --------------------------------------------------------------------- COMBINATION X ----------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS1.408-2.816.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000                               # The sky area this covariance was measured on
SurveyArea = 1000                           # Survey size you want to scale the cov to.

Nreal = 217

PlotLabel =  r'$\rm{PDF}$ Combined' ### r'$\rm{PDF} \,, \sigma_{\rm s} = 3.3 + 6.6 \, \rm{arcmin}$'
PlotColour = 'orange'

SmoothContour = False                    # Can optionally Gaussian smooth the likelihood contours if they're noisy
SmoothScale = 2                          # standev of smoothin kernel, in units of pxls on the grid.

CombName = SNR-SS3.3arcmin-6.6arcmin-tomo15bins_IA0.0-added 


# --------------------------------------------------------------------- COMBINATION X ----------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.27_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.9-1.2/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS1.408-2.816-5.631.SNRPDF_4bins.zbins11-12-13-14-15-22-23-24-25-33-34-35-44-45-55.CovMat.npy

CovArea = 1000                               # The sky area this covariance was measured on
SurveyArea = 1000                           # Survey size you want to scale the cov to.

Nreal = 217

PlotLabel =  r'$\rm{PDF}$ Combined' ### r'$\rm{PDF} \,, \sigma_{\rm s} = 3.3 + 6.6 + 13.2 \, \rm{arcmin}$'
PlotColour = 'orange'

SmoothContour = False                    # Can optionally Gaussian smooth the likelihood contours if they're noisy
SmoothScale = 2                          # standev of smoothin kernel, in units of pxls on the grid.

CombName = SNR-SS3.3arcmin-6.6arcmin-13.2arcmin-tomo15bins_IA0.0-added 


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Mass_Recon/MRres140.64arcs_100Sqdeg_SN0.265_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2/SN0.265_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.SNRPDF_4bins.CovMat.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000																			# Survey size you want to scale the cov to.

Nreal = 217

PlotLabel = r'$\rm{PDF} \,, \sigma_{\rm s} = 6.6 \, \rm{arcmin}$; No Tomo'
PlotColour = 'lightgreen'

CombName = SNR-SS6.6arcmin-NoTomo_IA0.0-added 






#x#x#x#x#x Unclipped xi+/- Combinations #x#x#x#x#x


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC+.CovMat.zbins1-2-3-4-5.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000												# Survey size you want to scale the cov to.
Nreal = 2170													# Num realisations in cov  
																# Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'Auto. $\xi_+$'
PlotColour = 'magenta'

CombName = Unclipped-xip-tomo5bins_ScaleCut6.6arcmin_IA0.0-added 


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC+.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000												# Survey size you want to scale the cov to.
Nreal = 2170													# Num realisations in cov  
																# Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'Auto & Cross $\xi_+$'
PlotColour = 'magenta'

CombName = Unclipped-xip-tomo15bins_ScaleCut6.6arcmin_IA0.0-added   


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000												# Survey size you want to scale the cov to.
Nreal = 2170													# Num realisations in cov  
																# Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'Auto & Cross $\xi_-$'
PlotColour = 'cyan'

CombName = Unclipped-xim-tomo15bins_ScaleCut6.6arcmin_IA0.0-added   



# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000									
SurveyArea = 1000								
Nreal = 217										

PlotLabel = r'$\xi_\pm$; $A_{\rm IA}=-3.0$'
PlotColour = 'lightblue'

CombName = Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA-3.0-added   

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000
SurveyArea = 1000
Nreal = 217

PlotLabel = r'$\xi_\pm$; $A_{\rm IA}=0.0$'
PlotColour = 'cyan'

CombName = Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA0.0-added

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000
SurveyArea = 1000
Nreal = 217

PlotLabel = r'$\xi_\pm$; $A_{\rm IA}=3.0$'
PlotColour = 'darkblue'

CombName = Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA3.0-added



# %%%% CLIPPED %%%%

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.CxC+.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000									
SurveyArea = 1000								
Nreal = 2170

PlotLabel = r'Auto & Cross $\xi_+$'
PlotColour = 'magenta'

CombName = Clipped-xip-tomo15bins_ScaleCut6.6arcmin_IA0.0-added   











# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.CxC-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000													# The sky area this covariance was measured on
SurveyArea = 1000												# Survey size you want to scale the cov to.
Nreal = 2170													# Num realisations in cov  
																# Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'Auto & Cross $\xi_-^{\rm c}$'
PlotColour = 'cyan'

CombName = Clipped-xim-tomo15bins_ScaleCut6.6arcmin_IA0.0-added   



# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.CxC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000									
SurveyArea = 1000								
Nreal = 2170									

PlotLabel = r'$\xi_\pm^{\rm c}$; $A_{\rm IA}=-3.0$'
PlotColour = 'pink'

CombName = Clipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA-3.0-added

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.CxC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000
SurveyArea = 1000
Nreal = 2170

PlotLabel = r'$\xi_\pm^{\rm c}$; $A_{\rm IA}=0.0$'
PlotColour = 'magenta'

CombName = Clipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA0.0-added

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.CxC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000
SurveyArea = 1000
Nreal = 2170

PlotLabel = r'$\xi_\pm^{\rm c}$; $A_{\rm IA}=3.0$'
PlotColour = 'purple'

CombName = Clipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA3.0-added


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.ClipAndUnclip+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000			
SurveyArea = 1000		
Nreal = 2170			
				
PlotLabel = r'$\xi_\pm^{\rm c & uc}$; $A_{\rm IA}=-3.0$'
PlotColour = 'lightgrey'

CombName = Clipped-Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA-3.0-added

# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.ClipAndUnclip+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy
			
CovArea = 1000			
SurveyArea = 1000		
Nreal = 2170			
				
PlotLabel = r'$\xi_\pm^{\rm c & uc}$; $A_{\rm IA}=0.0$'
PlotColour = 'black'

CombName = Clipped-Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA0.0-added   


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.ClipAndUnclip+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000			
SurveyArea = 1000		
Nreal = 2170			
				
PlotLabel = r'$\xi_\pm^{\rm c & uc}$; $A_{\rm IA}=3.0$'
PlotColour = 'dimgrey'

CombName = Clipped-Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA3.0-added


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2/ThBins9/NLOS2170/SN0.265_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.UCxUC+-.CovMat.npy

CovArea = 1000                   # The sky area this covariance was measured on
SurveyArea = 1000               # Survey size you want to scale the cov to.
Nreal = 2170                    # Num realisations in cov
                                # Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'$\xi_\pm^{\rm uc}$; No Tomo'
PlotColour = 'magenta'

CombName = Unclipped-xipm-NoTomo_ScaleCut6.6arcmin_IA0.0-added  


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2/ThBins9/NLOS2170/SN0.265_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.CxC+-.CovMat.npy

CovArea = 1000                   # The sky area this covariance was measured on
SurveyArea = 1000               # Survey size you want to scale the cov to.
Nreal = 2170                    # Num realisations in cov
                                # Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'$\xi_\pm^{\rm c}$; No Tomo'
PlotColour = 'cyan'

CombName = Clipped-xipm-NoTomo_ScaleCut6.6arcmin_IA0.0-added  


# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-1.2/ThBins9/NLOS2170/SN0.265_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.SS2.816.rCLIP_X3sigma.ClipAndUnclip+-.CovMat.npy

CovArea = 1000                   # The sky area this covariance was measured on
SurveyArea = 1000               # Survey size you want to scale the cov to.
Nreal = 2170                    # Num realisations in cov
                                # Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'$\xi_\pm^{\rm c & uc}$; No Tomo'
PlotColour = 'black'

CombName = Clipped-Unclipped-xipm-NoTomo_ScaleCut6.6arcmin_IA0.0-added 



# --------------------------------------------------------------------- COMBINATION X ------------------------------------------------------------------------------
CovFile = /home/bengib/Clipping_Pipeline/Tree_Correlation_Function/MRres140.64arcs_100Sqdeg_SNCycle_Mosaic_KiDS1000GpAM_zKiDS1000_ZBcut0.1-0.3_X_ZBcut0.1-0.3/ThBins9/NLOS2170/SN0.27_Mosaic.KiDS1000GpAM.NLOS2170-Shuffle0.ORIG.PDF-UCxUC+-.CovMat.zbins11_12_13_14_15_22_23_24_25_33_34_35_44_45_55.npy

CovArea = 1000                   # The sky area this covariance was measured on
SurveyArea = 1000               # Survey size you want to scale the cov to.
Nreal = 2170                   # Num realisations in cov
                                # Used to calc Hartlap correction if Apply Hartlap is True.

PlotLabel = r'PDF Combined {\&} $\xi_\pm^{\rm uc}$'
PlotColour = 'magenta'

CombName = SNR-SS6.6arcmin-Unclipped-xipm-tomo15bins_ScaleCut6.6arcmin_IA0.0-added 

